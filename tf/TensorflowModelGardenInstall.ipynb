{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4b6ce70",
   "metadata": {},
   "source": [
    "# This file was intended to load [Tensorflow Model Garden](https://www.tensorflow.org/guide/model_garden) Models for detection, and to verify GPU's are correctly interacting with Tensorflow\n",
    "## This turned out to be more of a pain and an existing installation was used instead\n",
    "### Consider this a 'just in case' file\n",
    "\n",
    "[Model Garden Git](https://github.com/tensorflow/models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5ce2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import cv2 \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66937bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "# import object_detection.utils as utils\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0084489",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jan 13 22:34:35 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:17:00.0 Off |                  N/A |\n",
      "|  0%   34C    P8     7W / 260W |     10MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:18:00.0 Off |                  N/A |\n",
      "|  0%   32C    P8    12W / 260W |     10MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA GeForce ...  On   | 00000000:65:00.0  On |                  N/A |\n",
      "|  0%   39C    P8    27W / 260W |    586MiB / 11264MiB |      6%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA GeForce ...  On   | 00000000:B3:00.0 Off |                  N/A |\n",
      "|  0%   32C    P8    11W / 260W |     10MiB / 11264MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2467      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A      3675      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A      2467      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A      3675      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    2   N/A  N/A      2467      G   /usr/lib/xorg/Xorg                 18MiB |\n",
      "|    2   N/A  N/A      2628      G   /usr/bin/gnome-shell               71MiB |\n",
      "|    2   N/A  N/A      3675      G   /usr/lib/xorg/Xorg                272MiB |\n",
      "|    2   N/A  N/A      3862      G   /usr/bin/gnome-shell               30MiB |\n",
      "|    2   N/A  N/A     12737      G   /usr/lib/firefox/firefox          173MiB |\n",
      "|    2   N/A  N/A     14144      G   ...871529856354221756,131072       16MiB |\n",
      "|    3   N/A  N/A      2467      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A      3675      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Jun__8_16:49:14_PDT_2022\n",
      "Cuda compilation tools, release 11.7, V11.7.99\n",
      "Build cuda_11.7.r11.7/compiler.31442593_0\n",
      "Python Version:  3.9.8\n",
      "Tensorflow/Keras Version:  2.10.0\n",
      "Devices:\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7550441127707648979\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10096803840\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 13712760107210553926\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:17:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10096803840\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3679448371643798268\n",
      "physical_device_desc: \"device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:18:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 2144165316\n",
      ", name: \"/device:GPU:2\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 9482993664\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6111491761266962630\n",
      "physical_device_desc: \"device: 2, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 1651660799\n",
      ", name: \"/device:GPU:3\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10096803840\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2142272148652993132\n",
      "physical_device_desc: \"device: 3, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:b3:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 878896533\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-13 22:34:35.627122: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-13 22:34:43.107333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:0 with 9629 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:17:00.0, compute capability: 7.5\n",
      "2023-01-13 22:34:43.116742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:1 with 9629 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:18:00.0, compute capability: 7.5\n",
      "2023-01-13 22:34:43.117845: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:2 with 9043 MB memory:  -> device: 2, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5\n",
      "2023-01-13 22:34:43.118891: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /device:GPU:3 with 9629 MB memory:  -> device: 3, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:b3:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!nvcc -V\n",
    "sys.path.append('..')\n",
    "print('Python Version: ', sys.version.split()[0])\n",
    "print('Tensorflow/Keras Version: ', tf.__version__)\n",
    "print('Devices:')\n",
    "print(device_lib.list_local_devices()) # check active GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99538818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n",
      "remote: Enumerating objects: 3657, done.\u001b[K\n",
      "remote: Counting objects: 100% (3657/3657), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3053/3053), done.\u001b[K\n",
      "remote: Total 3657 (delta 969), reused 1570 (delta 552), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (3657/3657), 47.39 MiB | 6.23 MiB/s, done.\n",
      "Resolving deltas: 100% (969/969), done.\n"
     ]
    }
   ],
   "source": [
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "    while \"models\" in pathlib.Path.cwd().parts:\n",
    "        os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "    !git clone --depth 1 https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab80163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "ls\n",
    "cd models/\n",
    "ls\n",
    "cd research/\n",
    "protoc object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f380aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_ops.tf = tf.compat.v1\n",
    "tf.gfile = tf.io.gfile\n",
    "\n",
    "def load_model(model_name):\n",
    "    base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
    "    model_file = model_name + '.tar.gz'\n",
    "    model_dir = tf.keras.utils.get_file(\n",
    "    fname=model_name, \n",
    "    origin=base_url + model_file,\n",
    "    untar=True)\n",
    "\n",
    "    model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
    "    model = tf.saved_model.load(str(model_dir))\n",
    "\n",
    "    return model\n",
    "\n",
    "model_name = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
    "detection_model = load_model(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
